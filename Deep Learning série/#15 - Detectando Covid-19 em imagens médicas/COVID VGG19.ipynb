{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REFERÊNCIAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IDEIA ORIGINAL: <br/>\n",
    "Adam Rosembrock <br/>\n",
    "pyimagesearch.com - \n",
    "https://www.pyimagesearch.com/2020/03/16/detecting-covid-19-in-x-ray-images-with-keras-tensorflow-and-deep-learning/\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ATENÇÃO\n",
    "\n",
    "Os métodos e técnicas usados neste vídeo são apenas para fins educacionais. Esse não é um estudo cientificamente rigoroso, nem será publicado em uma revista científica´."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AGENDA\n",
    "\n",
    "Dentro do tutorial de hoje, você aprenderá como:\n",
    "\n",
    "- Abrir uma base de imagens de raio-X  (open data) de pacientes com resultado POSITIVO para COVID-19 e imagens de pacientes com resultado NEGATIVO.\n",
    "\n",
    "\n",
    "- Dividir o dataset de imagens em conjunto de teste e conjunto de treino \n",
    "\n",
    "\n",
    "- Aplicar a técnica de aumento de dados (Data Augmentation)\n",
    "\n",
    "\n",
    "\n",
    "- Aplicar a técnica de transferência de inteligência entre redes neurais (Transfer Learning)\n",
    "\n",
    "\n",
    "- Treinar uma Rede Neural Convolucional com o Tensorflow/Keras para detectar automaticamente o COVID-19 em imagens de raios-X \n",
    "\n",
    "\n",
    "- Avaliar os resultados sob uma perspectiva educacional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importações de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from os import listdir\n",
    "from os.path import isdir\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando uma imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_image(filename):\n",
    "    # load image from file\n",
    "    image = Image.open(filename)\n",
    "    # convert to RGB, if needed\n",
    "    image = image.convert('RGB')\n",
    "    image = image.resize((150,150))\n",
    "    # convert to array\n",
    "    return np.asarray(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando uma classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_classes(diretorio, classe, imagens, labels):\n",
    "    # iterando arquivos\n",
    "\n",
    "    for filename in listdir(diretorio):\n",
    "\n",
    "        path = diretorio + filename\n",
    "\n",
    "        try:\n",
    "            imagens.append(select_image(path))\n",
    "            labels.append(classe)\n",
    "        except:\n",
    "            print(\"Erro ao ler imagem {}\".format(path))\n",
    "\n",
    "    return imagens, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecionando Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_data_set(diretorio):\n",
    "\n",
    "    imagens = list()\n",
    "    labels = list()\n",
    "\n",
    "    for subdir in listdir(diretorio):\n",
    "        # path\n",
    "        path = diretorio + subdir + '\\\\'\n",
    "\n",
    "        if not isdir(path):\n",
    "            continue\n",
    "        imagens, labels = load_classes(path, subdir, imagens, labels)\n",
    "\n",
    "    return imagens, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando dataset Covid-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_dataset = \"D:\\\\dataset\\\\covid-sandeco\\\\images\\\\\"\n",
    "imagens, labels  = select_data_set(covid_dataset)\n",
    "imagens = np.array(imagens) / 255.0  ## convertendo de lista para array\n",
    "labels = np.array(labels)  ## convertendo de lista para array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratando classes - Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo hyperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size   = 32\n",
    "input_shape  = (150, 150, 3)\n",
    "random_state = 42\n",
    "alpha        = 1e-5\n",
    "epoch        = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CALLBACKS\n",
    "\n",
    "Callback são classes que auxiliam o treinamento do modelo usando o Keras. As classes que usaremos são:\n",
    "\n",
    "- ModelCheckpoint\n",
    "- ReduceLROnPlateau\n",
    "- EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ModelCheckpoint\n",
    "\n",
    "ModelCheckpoint nos ajudará a salvar o modelo para cada época, para que possamos treinar nosso modelo e não nos preocuparmos com possíveis problemas que possam acontecer, como travamento da máquina.\n",
    "\n",
    "- **filepath**: onde será salvo o modelo\n",
    "- **monitor**: métrica a ser monitorada\n",
    "- **verbose**: (1) mostra na barra de progresso (0) não\n",
    "- **save_best_only**: Salvar somente o melhor modelo\n",
    "- **mode**: como vamos monitorar o 'val_acc' o valor aqui vai ser 'max'. Queremos a máxima acurácia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"transferlearning_weights.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ReduceLROnPlateau\n",
    "\n",
    "Nos auxiliara a reduzir a taxa de aprendizado pelo fator (factor) caso não ocorra a mudança no loss.\n",
    "\n",
    "- **monitor**: métrica a ser monitorada\n",
    "- **factor**: fator de redução caso estejamos em um plator\n",
    "- **min_delta**: valor mínimo da perda\n",
    "- **patience**: só altere pelo fator após se repitir por 'patience' vezes.\n",
    "- **verbose**: (1) mostra na barra de progresso (0) não\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.1, min_delta=alpha, patience=5, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array de Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [checkpoint, lr_reduce]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Particionando dataset em teste e treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, testX, trainY, testY) = train_test_split(imagens, labels, test_size=0.20, stratify=labels, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA AUGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        zoom_range=0.2)\n",
    "\n",
    "train_datagen.fit(trainX)\n",
    "\n",
    "data_aug = train_datagen.flow(trainX, trainY, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRANSFER LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = VGG19(weights='imagenet', include_top=False, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retreinando parte da VGG19\n",
    "\n",
    "\n",
    "explicar aqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = True\n",
    "set_trainable = False\n",
    "\n",
    "for layer in conv_base.layers:\n",
    "  if layer.name == 'block5_conv1':\n",
    "    set_trainable = True\n",
    "  if set_trainable:\n",
    "    layer.trainable = True\n",
    "  else:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 9,439,232\n",
      "Non-trainable params: 10,585,152\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRIANDO O MODELO COM A VGG19 COMO BASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.6))\n",
    "model.add(layers.Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg19 (Model)                (None, 4, 4, 512)         20024384  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 20,092,354\n",
      "Trainable params: 9,506,178\n",
      "Non-trainable params: 10,586,176\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMPILANDO O MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TREINANDO O MODELO\n",
    "\n",
    "***Obs: não treinar na hora da live***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.7788 - acc: 0.4922Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 13ms/sample - loss: 1.6575 - acc: 0.5000\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.50000, saving model to transferlearning_weights.hdf5\n",
      "3/3 [==============================] - 3s 841ms/step - loss: 0.6585 - acc: 0.5286 - val_loss: 1.3463 - val_acc: 0.5000\n",
      "Epoch 2/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.1965 - acc: 0.9211Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 1.5400 - acc: 0.8077\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.50000 to 0.80769, saving model to transferlearning_weights.hdf5\n",
      "3/3 [==============================] - 1s 249ms/step - loss: 0.2221 - acc: 0.9000 - val_loss: 1.5400 - val_acc: 0.8077\n",
      "Epoch 3/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.2141 - acc: 0.9062Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 7ms/sample - loss: 0.1235 - acc: 0.9808\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.80769 to 0.98077, saving model to transferlearning_weights.hdf5\n",
      "3/3 [==============================] - 1s 283ms/step - loss: 0.1710 - acc: 0.9143 - val_loss: 0.0725 - val_acc: 0.9808\n",
      "Epoch 4/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.1606 - acc: 0.9453Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 5ms/sample - loss: 29.2789 - acc: 0.5000\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 190ms/step - loss: 0.1370 - acc: 0.9583 - val_loss: 29.2789 - val_acc: 0.5000\n",
      "Epoch 5/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.1875 - acc: 0.9062Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 26.8269 - acc: 0.5000\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 193ms/step - loss: 0.1822 - acc: 0.9167 - val_loss: 26.8269 - val_acc: 0.5000\n",
      "Epoch 6/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0393 - acc: 1.0000Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 21.5697 - acc: 0.5000\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 0.0738 - acc: 0.9714 - val_loss: 21.5697 - val_acc: 0.5000\n",
      "Epoch 7/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.2841 - acc: 0.9342Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 9.8648 - acc: 0.5192\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.1883 - acc: 0.9500 - val_loss: 9.8648 - val_acc: 0.5192\n",
      "Epoch 8/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0789 - acc: 1.0000Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 14.4294 - acc: 0.5000\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.98077\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "3/3 [==============================] - 1s 192ms/step - loss: 0.1282 - acc: 0.9714 - val_loss: 14.4294 - val_acc: 0.5000\n",
      "Epoch 9/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.1365 - acc: 0.9453Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 9.3561 - acc: 0.5000\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 193ms/step - loss: 0.1118 - acc: 0.9531 - val_loss: 9.3561 - val_acc: 0.5000\n",
      "Epoch 10/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0590 - acc: 1.0000Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 7ms/sample - loss: 10.9349 - acc: 0.5000\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 190ms/step - loss: 0.0534 - acc: 1.0000 - val_loss: 7.7791 - val_acc: 0.5000\n",
      "Epoch 11/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.1910 - acc: 0.9531Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 7ms/sample - loss: 8.9405 - acc: 0.5385\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 178ms/step - loss: 0.1633 - acc: 0.9571 - val_loss: 6.0568 - val_acc: 0.5385\n",
      "Epoch 12/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0406 - acc: 0.9922Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 5ms/sample - loss: 4.9010 - acc: 0.5385\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 193ms/step - loss: 0.0422 - acc: 0.9948 - val_loss: 4.9010 - val_acc: 0.5385\n",
      "Epoch 13/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.3915 - acc: 0.8947Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 5ms/sample - loss: 3.9562 - acc: 0.5577\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.98077\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.2360 - acc: 0.9429 - val_loss: 3.9562 - val_acc: 0.5577\n",
      "Epoch 14/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0346 - acc: 1.0000Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 5ms/sample - loss: 3.2279 - acc: 0.5769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00014: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 184ms/step - loss: 0.0417 - acc: 0.9929 - val_loss: 3.2279 - val_acc: 0.5769\n",
      "Epoch 15/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0869 - acc: 0.9688Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 5ms/sample - loss: 2.7261 - acc: 0.5962\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 0.0669 - acc: 0.9792 - val_loss: 2.7261 - val_acc: 0.5962\n",
      "Epoch 16/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.1221 - acc: 0.9605Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 2.6181 - acc: 0.5962\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.1338 - acc: 0.9643 - val_loss: 2.6181 - val_acc: 0.5962\n",
      "Epoch 17/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0843 - acc: 0.9688Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 7ms/sample - loss: 5.1387 - acc: 0.6154\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 186ms/step - loss: 0.0808 - acc: 0.9714 - val_loss: 3.0239 - val_acc: 0.6154\n",
      "Epoch 18/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0268 - acc: 1.0000Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 5ms/sample - loss: 2.1612 - acc: 0.6154\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.98077\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "3/3 [==============================] - 1s 195ms/step - loss: 0.0336 - acc: 0.9896 - val_loss: 2.1612 - val_acc: 0.6154\n",
      "Epoch 19/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.1816 - acc: 0.9737Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 1.9385 - acc: 0.6923\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.1077 - acc: 0.9857 - val_loss: 1.9385 - val_acc: 0.6923\n",
      "Epoch 20/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0701 - acc: 0.9688Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 7ms/sample - loss: 4.0474 - acc: 0.7500\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 190ms/step - loss: 0.0548 - acc: 0.9714 - val_loss: 2.2339 - val_acc: 0.7500\n",
      "Epoch 21/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0534 - acc: 1.0000Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 5ms/sample - loss: 1.5120 - acc: 0.7692\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0428 - acc: 1.0000 - val_loss: 1.5120 - val_acc: 0.7692\n",
      "Epoch 22/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.2701 - acc: 0.9474Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 5ms/sample - loss: 1.3513 - acc: 0.7692\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.1651 - acc: 0.9643 - val_loss: 1.3513 - val_acc: 0.7692\n",
      "Epoch 23/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0443 - acc: 0.9844Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 1.2202 - acc: 0.7692\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.98077\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 0.0527 - acc: 0.9844 - val_loss: 1.2202 - val_acc: 0.7692\n",
      "Epoch 24/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.1504 - acc: 0.9297Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 7ms/sample - loss: 3.0289 - acc: 0.7692\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 185ms/step - loss: 0.1210 - acc: 0.9357 - val_loss: 1.5363 - val_acc: 0.7692\n",
      "Epoch 25/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0520 - acc: 0.9844Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 5ms/sample - loss: 0.9938 - acc: 0.7692\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 190ms/step - loss: 0.0471 - acc: 0.9896 - val_loss: 0.9938 - val_acc: 0.7692\n",
      "Epoch 26/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 1.2187 - acc: 0.9605Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 0.8715 - acc: 0.7692\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 204ms/step - loss: 0.7099 - acc: 0.9429 - val_loss: 0.8715 - val_acc: 0.7692\n",
      "Epoch 27/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0493 - acc: 1.0000Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 0.7879 - acc: 0.7692\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0556 - acc: 0.9857 - val_loss: 0.7879 - val_acc: 0.7692\n",
      "Epoch 28/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0476 - acc: 1.0000Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 7ms/sample - loss: 2.3907 - acc: 0.7885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00028: val_acc did not improve from 0.98077\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "3/3 [==============================] - 1s 178ms/step - loss: 0.0403 - acc: 1.0000 - val_loss: 1.1277 - val_acc: 0.7885\n",
      "Epoch 29/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0814 - acc: 0.9531Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 0.6690 - acc: 0.8077\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 188ms/step - loss: 0.0635 - acc: 0.9688 - val_loss: 0.6690 - val_acc: 0.8077\n",
      "Epoch 30/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0393 - acc: 0.9737Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 0.6414 - acc: 0.8077\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 179ms/step - loss: 0.0332 - acc: 0.9857 - val_loss: 0.6414 - val_acc: 0.8077\n",
      "Epoch 31/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0247 - acc: 1.0000Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 0.5723 - acc: 0.8077\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 188ms/step - loss: 0.0263 - acc: 1.0000 - val_loss: 0.5723 - val_acc: 0.8077\n",
      "Epoch 32/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0457 - acc: 0.9844Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 7ms/sample - loss: 1.9537 - acc: 0.8077\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 182ms/step - loss: 0.0404 - acc: 0.9857 - val_loss: 0.8721 - val_acc: 0.8077\n",
      "Epoch 33/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0363 - acc: 0.9844Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 7ms/sample - loss: 1.8458 - acc: 0.8077\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.98077\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "3/3 [==============================] - 1s 180ms/step - loss: 0.0424 - acc: 0.9857 - val_loss: 0.8080 - val_acc: 0.8077\n",
      "Epoch 34/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0506 - acc: 0.9844Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 5ms/sample - loss: 0.4590 - acc: 0.8077\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 194ms/step - loss: 0.0701 - acc: 0.9688 - val_loss: 0.4590 - val_acc: 0.8077\n",
      "Epoch 35/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0426 - acc: 1.0000Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 7ms/sample - loss: 1.6959 - acc: 0.8462\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.1528 - acc: 0.9773 - val_loss: 0.7230 - val_acc: 0.8462\n",
      "Epoch 36/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0569 - acc: 0.9922Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 0.3879 - acc: 0.8846\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 189ms/step - loss: 0.0465 - acc: 0.9948 - val_loss: 0.3879 - val_acc: 0.8846\n",
      "Epoch 37/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0507 - acc: 0.9737Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 0.3662 - acc: 0.8846\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 168ms/step - loss: 0.0603 - acc: 0.9714 - val_loss: 0.3662 - val_acc: 0.8846\n",
      "Epoch 38/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0583 - acc: 0.9766Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 7ms/sample - loss: 1.4481 - acc: 0.8846\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.98077\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "3/3 [==============================] - 1s 192ms/step - loss: 0.0628 - acc: 0.9786 - val_loss: 0.5912 - val_acc: 0.8846\n",
      "Epoch 39/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0863 - acc: 0.9609Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 0.3084 - acc: 0.8846\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 201ms/step - loss: 0.0784 - acc: 0.9740 - val_loss: 0.3084 - val_acc: 0.8846\n",
      "Epoch 40/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.1051 - acc: 0.9688Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 7ms/sample - loss: 1.3383 - acc: 0.8846\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 178ms/step - loss: 0.1081 - acc: 0.9643 - val_loss: 0.5367 - val_acc: 0.8846\n",
      "Epoch 41/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.2341 - acc: 0.9342Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 0.2599 - acc: 0.8846\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.1520 - acc: 0.9643 - val_loss: 0.2599 - val_acc: 0.8846\n",
      "Epoch 42/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0392 - acc: 0.9922Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 0.2518 - acc: 0.8846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00042: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 203ms/step - loss: 0.0330 - acc: 0.9948 - val_loss: 0.2518 - val_acc: 0.8846\n",
      "Epoch 43/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.2190 - acc: 0.9737Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 0.2272 - acc: 0.9038\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.98077\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.1361 - acc: 0.9857 - val_loss: 0.2272 - val_acc: 0.9038\n",
      "Epoch 44/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0362 - acc: 1.0000Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 7ms/sample - loss: 1.1051 - acc: 0.9038\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 178ms/step - loss: 0.0312 - acc: 1.0000 - val_loss: 0.4259 - val_acc: 0.9038\n",
      "Epoch 45/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0439 - acc: 0.9868Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 0.2051 - acc: 0.9423\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0627 - acc: 0.9857 - val_loss: 0.2051 - val_acc: 0.9423\n",
      "Epoch 46/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0718 - acc: 0.9737Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 0.2009 - acc: 0.9423\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0775 - acc: 0.9714 - val_loss: 0.2009 - val_acc: 0.9423\n",
      "Epoch 47/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.1076 - acc: 0.9688Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 0.1934 - acc: 0.9423\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 195ms/step - loss: 0.0804 - acc: 0.9792 - val_loss: 0.1934 - val_acc: 0.9423\n",
      "Epoch 48/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0363 - acc: 0.9922Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 7ms/sample - loss: 0.9527 - acc: 0.9423\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.98077\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "3/3 [==============================] - 1s 178ms/step - loss: 0.0536 - acc: 0.9857 - val_loss: 0.3615 - val_acc: 0.9423\n",
      "Epoch 49/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0390 - acc: 1.0000Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 7ms/sample - loss: 0.8947 - acc: 0.9615\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 178ms/step - loss: 0.0450 - acc: 1.0000 - val_loss: 0.3367 - val_acc: 0.9615\n",
      "Epoch 50/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.2844 - acc: 0.9474Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 0.1570 - acc: 0.9615\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.1934 - acc: 0.9571 - val_loss: 0.1570 - val_acc: 0.9615\n",
      "Epoch 51/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0502 - acc: 0.9844Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 5ms/sample - loss: 0.1503 - acc: 0.9615\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 195ms/step - loss: 0.0620 - acc: 0.9688 - val_loss: 0.1503 - val_acc: 0.9615\n",
      "Epoch 52/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0514 - acc: 1.0000Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 0.1469 - acc: 0.9615\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0364 - acc: 1.0000 - val_loss: 0.1469 - val_acc: 0.9615\n",
      "Epoch 53/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0309 - acc: 1.0000Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 5ms/sample - loss: 0.1419 - acc: 0.9615\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.98077\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
      "3/3 [==============================] - 1s 193ms/step - loss: 0.0427 - acc: 0.9948 - val_loss: 0.1419 - val_acc: 0.9615\n",
      "Epoch 54/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0331 - acc: 1.0000Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 0.1345 - acc: 0.9615\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 188ms/step - loss: 0.0327 - acc: 1.0000 - val_loss: 0.1345 - val_acc: 0.9615\n",
      "Epoch 55/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.3984 - acc: 0.9211Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 7ms/sample - loss: 0.7054 - acc: 0.9615\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.2470 - acc: 0.9318 - val_loss: 0.2630 - val_acc: 0.9615\n",
      "Epoch 56/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0402 - acc: 0.9922Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 0.1228 - acc: 0.9615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00056: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 188ms/step - loss: 0.0517 - acc: 0.9844 - val_loss: 0.1228 - val_acc: 0.9615\n",
      "Epoch 57/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0941 - acc: 0.9342Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 0.1197 - acc: 0.9615\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0807 - acc: 0.9643 - val_loss: 0.1197 - val_acc: 0.9615\n",
      "Epoch 58/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0591 - acc: 0.9844Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 0.1176 - acc: 0.9615\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.98077\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 1.0000001179769417e-14.\n",
      "3/3 [==============================] - 1s 200ms/step - loss: 0.0473 - acc: 0.9896 - val_loss: 0.1176 - val_acc: 0.9615\n",
      "Epoch 59/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0890 - acc: 0.9737Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 0.1128 - acc: 0.9615\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 186ms/step - loss: 0.0919 - acc: 0.9714 - val_loss: 0.1128 - val_acc: 0.9615\n",
      "Epoch 60/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0682 - acc: 0.9688Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 7ms/sample - loss: 0.5908 - acc: 0.9615\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 178ms/step - loss: 0.0593 - acc: 0.9714 - val_loss: 0.2223 - val_acc: 0.9615\n",
      "Epoch 61/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0610 - acc: 0.9737Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 0.1068 - acc: 0.9615\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0465 - acc: 0.9857 - val_loss: 0.1068 - val_acc: 0.9615\n",
      "Epoch 62/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0682 - acc: 0.9844Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 7ms/sample - loss: 0.5559 - acc: 0.9615\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 183ms/step - loss: 0.0703 - acc: 0.9857 - val_loss: 0.2107 - val_acc: 0.9615\n",
      "Epoch 63/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0726 - acc: 0.9688Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 0.1036 - acc: 0.9615\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.98077\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 1.0000001518582595e-15.\n",
      "3/3 [==============================] - 1s 189ms/step - loss: 0.0920 - acc: 0.9583 - val_loss: 0.1036 - val_acc: 0.9615\n",
      "Epoch 64/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.1008 - acc: 0.9605Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 0.1010 - acc: 0.9615\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0740 - acc: 0.9786 - val_loss: 0.1010 - val_acc: 0.9615\n",
      "Epoch 65/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0416 - acc: 1.0000Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 0.0981 - acc: 0.9615\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0407 - acc: 1.0000 - val_loss: 0.0981 - val_acc: 0.9615\n",
      "Epoch 66/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0312 - acc: 1.0000Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 0.0975 - acc: 0.9615\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0306 - acc: 1.0000 - val_loss: 0.0975 - val_acc: 0.9615\n",
      "Epoch 67/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0617 - acc: 0.9844Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 7ms/sample - loss: 0.4994 - acc: 0.9615\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 179ms/step - loss: 0.0812 - acc: 0.9857 - val_loss: 0.1925 - val_acc: 0.9615\n",
      "Epoch 68/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0508 - acc: 0.9844Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 0.0965 - acc: 0.9615\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.98077\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 1.0000001095066122e-16.\n",
      "3/3 [==============================] - 1s 189ms/step - loss: 0.0501 - acc: 0.9896 - val_loss: 0.0965 - val_acc: 0.9615\n",
      "Epoch 69/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0567 - acc: 0.9922Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 7ms/sample - loss: 0.4737 - acc: 0.9615\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 178ms/step - loss: 0.0455 - acc: 0.9929 - val_loss: 0.1846 - val_acc: 0.9615\n",
      "Epoch 70/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.1144 - acc: 0.9766Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 0.0947 - acc: 0.9615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00070: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 188ms/step - loss: 0.0860 - acc: 0.9844 - val_loss: 0.0947 - val_acc: 0.9615\n",
      "Epoch 71/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.1587 - acc: 0.9342Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 0.0939 - acc: 0.9615\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.1038 - acc: 0.9643 - val_loss: 0.0939 - val_acc: 0.9615\n",
      "Epoch 72/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0444 - acc: 0.9868Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 0.0923 - acc: 0.9615\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0368 - acc: 0.9929 - val_loss: 0.0923 - val_acc: 0.9615\n",
      "Epoch 73/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0185 - acc: 1.0000Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 0.0915 - acc: 0.9615\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.98077\n",
      "\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 1.0000000830368326e-17.\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0367 - acc: 0.9929 - val_loss: 0.0915 - val_acc: 0.9615\n",
      "Epoch 74/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0567 - acc: 1.0000Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 0.0896 - acc: 0.9615\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0590 - acc: 0.9857 - val_loss: 0.0896 - val_acc: 0.9615\n",
      "Epoch 75/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0381 - acc: 1.0000Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 0.0896 - acc: 0.9615\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 188ms/step - loss: 0.0410 - acc: 1.0000 - val_loss: 0.0896 - val_acc: 0.9615\n",
      "Epoch 76/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0675 - acc: 0.9609Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 7ms/sample - loss: 0.3886 - acc: 0.9615\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 179ms/step - loss: 0.1286 - acc: 0.9500 - val_loss: 0.1575 - val_acc: 0.9615\n",
      "Epoch 77/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.2099 - acc: 0.9737Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 0.0855 - acc: 0.9615\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.1279 - acc: 0.9857 - val_loss: 0.0855 - val_acc: 0.9615\n",
      "Epoch 78/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0717 - acc: 0.9766Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 0.0842 - acc: 0.9615\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.98077\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 1.0000000664932204e-18.\n",
      "3/3 [==============================] - 1s 196ms/step - loss: 0.0731 - acc: 0.9688 - val_loss: 0.0842 - val_acc: 0.9615\n",
      "Epoch 79/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0461 - acc: 1.0000Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 0.0834 - acc: 0.9615\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 199ms/step - loss: 0.0439 - acc: 0.9929 - val_loss: 0.0834 - val_acc: 0.9615\n",
      "Epoch 80/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0560 - acc: 0.9766Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 7ms/sample - loss: 0.3518 - acc: 0.9615\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 179ms/step - loss: 0.0451 - acc: 0.9786 - val_loss: 0.1456 - val_acc: 0.9615\n",
      "Epoch 81/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0800 - acc: 0.9766Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 5ms/sample - loss: 0.0813 - acc: 0.9615\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 190ms/step - loss: 0.0706 - acc: 0.9792 - val_loss: 0.0813 - val_acc: 0.9615\n",
      "Epoch 82/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.1078 - acc: 0.9737Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 7ms/sample - loss: 0.3425 - acc: 0.9615\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 184ms/step - loss: 0.0741 - acc: 0.9773 - val_loss: 0.1428 - val_acc: 0.9615\n",
      "Epoch 83/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0328 - acc: 1.0000Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 5ms/sample - loss: 0.0805 - acc: 0.9615\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.98077\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 1.000000045813705e-19.\n",
      "3/3 [==============================] - 1s 197ms/step - loss: 0.0353 - acc: 0.9948 - val_loss: 0.0805 - val_acc: 0.9615\n",
      "Epoch 84/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.1126 - acc: 0.9605Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 0.0797 - acc: 0.9615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00084: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0856 - acc: 0.9786 - val_loss: 0.0797 - val_acc: 0.9615\n",
      "Epoch 85/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0465 - acc: 0.9844Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 0.0790 - acc: 0.9615\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 191ms/step - loss: 0.0412 - acc: 0.9896 - val_loss: 0.0790 - val_acc: 0.9615\n",
      "Epoch 86/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0360 - acc: 1.0000Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 0.0781 - acc: 0.9615\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 189ms/step - loss: 0.0510 - acc: 0.9786 - val_loss: 0.0781 - val_acc: 0.9615\n",
      "Epoch 87/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.1537 - acc: 0.9605Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 0.0776 - acc: 0.9615\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 182ms/step - loss: 0.1124 - acc: 0.9643 - val_loss: 0.0776 - val_acc: 0.9615\n",
      "Epoch 88/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.3690 - acc: 0.9605Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 5ms/sample - loss: 0.0777 - acc: 0.9615\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.98077\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 1.000000032889008e-20.\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.2154 - acc: 0.9786 - val_loss: 0.0777 - val_acc: 0.9615\n",
      "Epoch 89/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0481 - acc: 0.9844Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 5ms/sample - loss: 0.0772 - acc: 0.9615\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 201ms/step - loss: 0.0605 - acc: 0.9792 - val_loss: 0.0772 - val_acc: 0.9615\n",
      "Epoch 90/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.1017 - acc: 0.9868Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 5ms/sample - loss: 0.0764 - acc: 0.9615\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 0.0635 - acc: 0.9929 - val_loss: 0.0764 - val_acc: 0.9615\n",
      "Epoch 91/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0560 - acc: 0.9474Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 7ms/sample - loss: 0.2997 - acc: 0.9615\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0521 - acc: 0.9545 - val_loss: 0.1290 - val_acc: 0.9615\n",
      "Epoch 92/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0450 - acc: 0.9844Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 5ms/sample - loss: 0.0758 - acc: 0.9615\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 190ms/step - loss: 0.0465 - acc: 0.9896 - val_loss: 0.0758 - val_acc: 0.9615\n",
      "Epoch 93/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0336 - acc: 1.0000Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 5ms/sample - loss: 0.0754 - acc: 0.9615\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.98077\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 1.0000000490448793e-21.\n",
      "3/3 [==============================] - 1s 194ms/step - loss: 0.0425 - acc: 0.9896 - val_loss: 0.0754 - val_acc: 0.9615\n",
      "Epoch 94/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0809 - acc: 1.0000Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 5ms/sample - loss: 0.0760 - acc: 0.9615\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 168ms/step - loss: 0.0556 - acc: 1.0000 - val_loss: 0.0760 - val_acc: 0.9615\n",
      "Epoch 95/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0346 - acc: 0.9922Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 7ms/sample - loss: 0.2925 - acc: 0.9615\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 181ms/step - loss: 0.0347 - acc: 0.9929 - val_loss: 0.1263 - val_acc: 0.9615\n",
      "Epoch 96/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0775 - acc: 0.9766Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 0.0748 - acc: 0.9615\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 190ms/step - loss: 0.1131 - acc: 0.9531 - val_loss: 0.0748 - val_acc: 0.9615\n",
      "Epoch 97/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0303 - acc: 0.9868Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 5ms/sample - loss: 0.0736 - acc: 0.9615\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0469 - acc: 0.9857 - val_loss: 0.0736 - val_acc: 0.9615\n",
      "Epoch 98/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0535 - acc: 1.0000Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 5ms/sample - loss: 0.0738 - acc: 0.9615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00098: val_acc did not improve from 0.98077\n",
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 1.0000000692397185e-22.\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 0.0629 - acc: 0.9844 - val_loss: 0.0738 - val_acc: 0.9615\n",
      "Epoch 99/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.1164 - acc: 0.9737Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 5ms/sample - loss: 0.0730 - acc: 0.9615\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 0.0846 - acc: 0.9857 - val_loss: 0.0730 - val_acc: 0.9615\n",
      "Epoch 100/100\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0553 - acc: 1.0000Epoch 1/100\n",
      "26/3 [====================================================================================================================================================================================================================================================================] - 0s 5ms/sample - loss: 0.0722 - acc: 0.9615\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.98077\n",
      "3/3 [==============================] - 1s 167ms/step - loss: 0.0558 - acc: 0.9857 - val_loss: 0.0722 - val_acc: 0.9615\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "                              data_aug,\n",
    "                              steps_per_epoch=len(trainX)// batch_size, # parte inteira da divisão\n",
    "                              validation_data=(testX, testY),\n",
    "                              validation_steps=len(testX) // batch_size,# parte inteira da divisão\n",
    "                              callbacks=callbacks,\n",
    "                              epochs=epoch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALISANDO DADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerando matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "pred = model.predict(testX)\n",
    "pred = np.argmax(pred,axis = 1) \n",
    "y_true = np.argmax(testY,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.9615\n",
      "Sensitividade: 1.0000\n",
      "Especificidade: 0.9231\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_true, pred)\n",
    "total = sum(sum(cm))\n",
    "acc = (cm[0, 0] + cm[1, 1]) / total\n",
    "sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
    "\n",
    "print(\"Acurácia: {:.4f}\".format(acc))\n",
    "print(\"Sensitividade: {:.4f}\".format(sensitivity))\n",
    "print(\"Especificidade: {:.4f}\".format(specificity))\n",
    "\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "fig, ax = plot_confusion_matrix(conf_mat=cm ,  figsize=(5, 5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Detector COVID-19 automático 96,15% de Acurácia.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também estamos obtendo 100% de sensibilidade e 92% de especificidade, o que implica que:\n",
    "\n",
    "- Sensibilidade, capacidade indentificar caso positivo de COVID-19 com o modelo é de 100%.\n",
    "\n",
    "\n",
    "- Especificidade, capacidade indentificar caso Não-Positivo de COVID-19 com o modelo é de 92,31%.\n",
    "\n",
    "\n",
    "- Como mostra nosso gráfico de histórico de treinamento, nossa rede não está adaptando demais, apesar de ter dados de treinamento limitado"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
